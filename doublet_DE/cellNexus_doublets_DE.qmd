---
title: "CellNexus Doublet Differential Expression Analysis"
author: "Mengyuan Shen"
format:
  html:
    theme: minty
    df-print: paged
    code-line-numbers: true
    embed-resources: true
    code-fold: true
    code-fold-default: true
knitr:
  opts_chunk:
    message: false
    warning: false
    echo: true
---

# Introduction

This report provides an overview of doublet differential expression analysis from cellNexus. It outlines the workflow steps, including data filtering, pseudobulk aggregation, quality control, dispersion estimation, DE analysis, and visualization.

```{r setup}
# .libPaths("/Library/Frameworks/R.framework/Versions/4.5-x86_64/Resources/library")

required_packages <- c(
  "stringr",
  "dplyr",
  "purrr",
  "ggplot2",
  "SummarizedExperiment",
  "SingleCellExperiment",
  "viridis",
  "ggrepel",
  "patchwork",
  "cellNexus",
  "tidySingleCellExperiment",
  "tidybulk",
  "edgeR",
  "tidySummarizedExperiment",
  "tidyr"
)

# Ensure rlang is present
if (!requireNamespace("rlang", quietly = TRUE)) {
  install.packages("rlang")
}

# Helper to check and install Bioc packages if missing

lapply(required_packages, function(pkg) {
  if (!rlang::is_installed(pkg)) {
    message(sprintf("Attempting to install missing package: %s", pkg))
    if (!requireNamespace("BiocManager", quietly = TRUE)) {
      install.packages("BiocManager")
    }
    BiocManager::install(pkg, ask = FALSE, update = FALSE)
    library(pkg, character.only = TRUE)
  }
})

```

# Load and process data
```{r}
library(targets)

tar_script({
  library(targets)
  library(crew)
  library(crew.cluster)
  # Helper (optional) to avoid repetition
  new_elastic <- function(name,
                          mem_gb,
                          time_min,
                          workers,
                          crashes_max,
                          backup = NULL) {
    crew_controller_slurm(
      name = name,
      workers = workers,
      crashes_max = crashes_max,
      seconds_idle = 30,
      options_cluster = crew_options_slurm(
        memory_gigabytes_required = mem_gb,
        cpus_per_task = 2,
        time_minutes = time_min
      ),
      backup = backup
    )
  }
  
  # Small → large, with fallbacks to the next size up
  elastic_160 <- new_elastic("elastic_160",
                             160,
                             60 * 24,
                             workers = 8,
                             crashes_max = 2)
  elastic_80  <- new_elastic(
    "elastic_80",
    80,
    60 * 4,
    workers = 16,
    crashes_max = 1,
    backup = elastic_160
  )
  elastic_40  <- new_elastic(
    "elastic_40",
    40,
    60 * 4,
    workers = 24,
    crashes_max = 1,
    backup = elastic_80
  )
  elastic_20  <- new_elastic(
    "elastic_20",
    20,
    60 * 4,
    workers = 32,
    crashes_max = 1,
    backup = elastic_40
  )
  elastic_10  <- new_elastic(
    "elastic_10",
    10,
    60 * 4,
    workers = 200,
    crashes_max = 1,
    backup = elastic_20
  )
  elastic_5   <- new_elastic(
    "elastic_5",
    5,
    60 * 4,
    workers = 200,
    crashes_max = 6,
    backup = elastic_10
  )
  
  # Group for targets (small → large)
  controllers <- crew_controller_group(elastic_5,
                                       elastic_10,
                                       elastic_20,
                                       elastic_40,
                                       elastic_80,
                                       elastic_160)
  
  tar_option_set(
    memory = "transient",
    garbage_collection = 100,
    storage = "worker",
    retrieval = "worker",
    #error = "continue",
    
    #cue = tar_cue(mode = "never"),
    
    workspace_on_error = TRUE,
    format = "qs",
    
    workspaces = "estimates_chunk_633f6596569029e6",
    debug = "sample_aggregated",
    
    controller = controllers
    
  )
  
  get_my_metadata <- function() {
    get_metadata() |>
      filter(empty_droplet == FALSE, alive == TRUE, feature_count >= 8000) |>
      mutate(scDblFinder.class %in% c("singlet", "doublet"))
  }
  
  list(
    tar_target(
      my_cache_directory,
      "/vast/projects/cellxgene_curated/cellNexus/"
    ),
    tar_target(my_doublet_proportion, 0.05),
    tar_target(
      my_sample_id,
      get_my_metadata() |>
        count(sample_id, dataset_id, scDblFinder.class) |>
        mutate(doublet_proportion = n / sum(n), .by = sample_id) |>
        filter(scDblFinder.class == "doublet") |>
        filter(doublet_proportion > my_doublet_proportion) |>
        
        # get datasets with most samples
        collect() |>
        nest(data = -dataset_id) |>
        mutate(n_samples = map_int(data, ~ n_distinct(.x$sample_id))) |>
        arrange(desc(n_samples)) |>
        filter(n_samples >= 10) |>
        unnest(data) |>
        pull(sample_id) |>
        unique() ,

      packages = c("cellNexus", "dplyr", "tidyr", "purrr"),
      iteration = "list"
    ),
    tar_target(
      sample_aggregated,
      {
        sce <-
          get_my_metadata() |>
          filter(sample_id == my_sample_id) |>
          get_single_cell_experiment(cache_directory = my_cache_directory)
        
        sce |>
          scuttle::aggregateAcrossCells(
            colData(sce)[, c("sample_id", "scDblFinder.class")] |>
              as_tibble(rownames = ".cell") |>
              mutate(
                aggregated_cells = paste(sample_id, scDblFinder.class, sep = "___")
              ) |>
              pull(aggregated_cells)
            # ,
            # BPPARAM = BiocParallel::MulticoreParam(
            #   workers = parallelly::availableCores()
            # )
          )
      },
      pattern = map(my_sample_id),
      iteration = "list",
      packages = c(
        "cellNexus",
        "scuttle",
        "dplyr",
        "BiocParallel",
        "parallelly"
      )
    ),
    
    # Get shared genes across all samples
    tar_target(
      genes_list,
      sample_aggregated |> rownames(),
      packages = c("SummarizedExperiment", "dplyr", "tidyr"),
      pattern = map(sample_aggregated),
      iteration = "list"
    ),
    tar_target(shared_genes, genes_list |> Reduce(intersect, x = _)),
    tar_target(
      sample_aggregated_filtered,
      {
        sample_aggregated =
          sample_aggregated[rownames(sample_aggregated) %in% shared_genes, ]
        
        rn = rownames(sample_aggregated)
        
        sample_aggregated =
          sample_aggregated |>
          as("SummarizedExperiment")
        
        rownames(sample_aggregated) = rn
        
        sample_aggregated
      },
      packages = c(
        "SummarizedExperiment",
        "dplyr",
        "tidyr",
        "tidySingleCellExperiment",
        "purrr"
      ),
      pattern = map(sample_aggregated),
      iteration = "list"
    ),
    tar_target(
      se_dataset,
      {
        se =
          sample_aggregated_filtered |>
          map(~ .x |> select(.feature, .sample, counts, contains("_id"), scDblFinder.class, ncells)) |> 
          do.call(cbind, args = _)
        
        dp =
          se |>
          pivot_sample() |>
          mutate(doublet_proportion = ncells / sum(ncells),
                 .by = sample_id) |>
          filter(scDblFinder.class == "doublet") |>
          distinct(sample_id, doublet_proportion)
        
        se |>
          left_join(dp) |>
          filter(doublet_proportion > my_doublet_proportion) |>
          filter(ncells > 10) |>
          filter(sample_id %in% (
            se |> pivot_sample() |> count(sample_id) |> filter(n == 2) |> pull(sample_id)
          )) |>
          filter(dataset_id %in% (
            se |> pivot_sample() |> count(dataset_id) |> filter(n > 10) |> pull(dataset_id)
          )) |>
          group_split(dataset_id) |> 
          
          # Filter small datasets
          map(~ { if(.x |> ncol() > 6 ) .x else NA}) |> 
          discard(is_na)
      },
      iteration = "list",
      packages = c("tidySummarizedExperiment", "SummarizedExperiment", "tidybulk", "rlang")
    ),
    tar_target(
      se_de,
      {
        se_dataset |>
          
          mutate(
            symbol = AnnotationDbi::mapIds(
              org.Hs.eg.db::org.Hs.eg.db,
              keys = .feature,
              keytype = "ENSEMBL",
              column = "SYMBOL",
              multiVals = "first"
            )
          ) |>
          mutate(
            entrez = AnnotationDbi::mapIds(
              org.Hs.eg.db::org.Hs.eg.db,
              keys = .feature,
              keytype = "ENSEMBL",
              column = "ENTREZID",
              multiVals = "first"
            )
          ) |>
          mutate(scDblFinder.class  = scDblFinder.class |> fct_relevel("singlet", "doublet")) |>
          
          keep_abundant(
            formula_design = ~ scDblFinder.class,
            minimum_count_per_million = 20
          )  |>
          scale_abundance(method = "TMMwsp") |>
          test_differential_expression(
            .formula = ~  scDblFinder.class + sample_id,
            scaling_method = "TMMwsp",
            test_above_log2_fold_change = 1,
            method = "edger_robust_likelihood_ratio",
          )
      },
      iteration = "list",
      pattern = map(se_dataset),
      packages = c(
        "org.Hs.eg.db",
        "tidySummarizedExperiment",
        "dplyr",
        "tidyr",
        "tidybulk",
        "purrr", "forcats"
      )
    ),
    tar_target(
      gsea,
      se_de |>
        
        filter(!entrez |> is.na()) |>
        filter(!entrez |> duplicated()) |>
        test_gene_rank(
          .entrez = entrez,
          species = "Homo sapiens",
          .arrange_desc = logFC,
          gene_sets = "c2"
        ),
      iteration = "list",
      pattern = map(se_de),
      packages = c(
        "tidySummarizedExperiment",
        "dplyr",
        "tidyr",
        "tidybulk",
        "purrr"
      )
    ),
    
    tar_target(
      gsea_plot,
      gsea |>
        
        unnest(test) |>
        filter(Description |> str_detect("ADH")) |>
        filter(p.adjust <= 0.05) |>
        mutate(plot = pmap(
          list(fit, ID, idx_for_plotting, p.adjust),
          ~ enrichplot::gseaplot2(
            ..1,
            geneSetID = ..3,
            title = sprintf("%s \nadj pvalue %s", ..2, round(..4, 2)),
            base_size = 6,
            rel_heights = c(1.5, 0.5),
            subplots = c(1, 2)
          )
        )) |>
        pull(plot),
      iteration = "list",
      pattern = map(gsea),
      packages = c(
        "tidySummarizedExperiment",
        "dplyr",
        "tidyr",
        "purrr", "stringr"
      )
    )
    
  )
}, ask = FALSE, script = here::here("doublet_DE", "_targets.R"))

tar_make(script = here::here("doublet_DE", "_targets.R"),
         store = "/vast/scratch/users/mangiola.s/doublet_DE/targets")

tar_workspace(
  se_dataset,
  script = here::here("doublet_DE", "_targets.R"),
 store = "/vast/scratch/users/mangiola.s/doublet_DE/targets"
)
```

```{r}


  tar_read(gsea, store = "/vast/scratch/users/mangiola.s/doublet_DE/targets")[[1]] |> 
     unnest(test) |>
        filter(Description |> str_detect("ADH"))


```

```{r Density}
# Count distribution
se |> 
  ggplot(aes(counts_scaled+1, group=scDblFinder.class)) +
  geom_density(aes(color = scDblFinder.class)) +
  scale_x_log10()
```



::: {.callout-note collapse="true" title="Session Info"}
```{r}
sessionInfo()
```
:::